
# cache 
因此L1 Cache也被划分成L1i (i for instruction)和L1d (d for data)两种专门用途的缓存

# cache contention
https://fgiesen.wordpress.com/2014/07/07/cache-coherency/



总线流量（bus traffic）和缓存一致性（cache coherency）。部分内存访问操作实际上会无法命中缓存，从而只能从内存中加载。一旦有些缓存段因为长时间无人访问而被丢弃，我们就要开始把它的内容回写（write-back）到内存中。所有这些事件都会导致总线上（以及内存中）发生通讯流量。而总线和内存的带宽是有限的，当容量饱和时，系统就变慢了。

而且，一旦我们在多核系统中运行多线程程序，总线上就会产生额外的通讯流量来保证缓存一致性，因为各个处理器都会不断地同步它们所看到的内存内容。如果每个线程都在自己独立的内存空间里工作，那么这种流量不会很大。如果每块内存只会被一个处理器使用，那么根本无需同步，而且我们可以很容易获取这些内存对应的缓存段的独占权，不会引起其他处理器上的缓存段失效。

相反，如果两个或多个处理器频繁地访问相同的缓存段，那么这些缓存段的内容必须保持同步。如果想更新其中一个缓存段的内容，必须先获得独占权，这意味着其他所有处理器必须先丢弃它们缓存中的同一缓存段的拷贝。这带来的结果是，下一次有另外一个处理器要访问这个缓存段，它的内容必须先通过总线来加载。所以结果就是缓存失效率（对于其他处理器来说）和总线上额外的通讯流量都增加了。这种多个处理器访问一个频繁被更新的缓存段的现象，叫做“缓存（段）竞争”。如果你想在多个处理器共用内存的环境中拖慢一个并行的程序，这也许是最简单的方法。

内存屏障和原子性的“读-修改-写”操作。下一步，假设我们的代码是多线程的，但我们还是在单核上运行它。这里我们就可以看到内存屏障和原子操作了，但是没有来自其他处理器的干扰。我们简单假设所有需要的缓存段已经被我们的处理器独占了。在这种情况下，使用一次原子的整数加法来更新内存中的一个引用计数器，代价到底有多大？

好吧，这其实取决于处理器架构的实现。一般来说，对于带有激进的内存重排序（memory reordering）策略的微架构处理器来说，使用内存屏障和原子操作的开销更大，而只支持轻度重排序或者顺序执行（in-order）内存操作的处理器则好一点。比如，在 Intel Atom处理器（顺序执行）上使用LOCK INC [mem]来增加引用计数器值的开销，本质上和使用常规INC [mem]指令是一样的。而更复杂的内存操作，如“交换（exchange）”和“交换-加(exchange-add)”花费的时间是基础的“读-修改-写”操作的两到三倍。相反，在Intel和AMD支持乱序执行（out-of-order）的桌面处理器产品线中，一次原子自加操作的开销是非原子版本的十到二十五倍，这些开销是保证正确的执行顺序所带来的。再一次重申：这仅是在单核上运行的代码，还没有涉及处理器间通讯的开销。为了使代码在多核系统上安全地运行，还会在单个处理器内引入额外的开销。


False sharing is also known as cache-line ping-ponging

if the two variables are located in the same cache line and at least one is being written, then there will be contention for that cache line.
This is false sharing.
